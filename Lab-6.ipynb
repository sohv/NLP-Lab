{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5809e4e0-a927-4e21-90a5-d042fced6d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /opt/anaconda3/lib/python3.12/site-packages (2.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b016a5bf",
   "metadata": {},
   "source": [
    "# Noise removal for textual data and remove regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc5965c-8805-4b9b-a542-04983f3f859c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: This is a sample tweet with #hashtag and a link http://example.com!\n",
      "Cleaned Sentence: This is a sample tweet with  and a link\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_noise(text):\n",
    "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n",
    "    return text.strip()\n",
    "\n",
    "sentence = \"This is a sample tweet with #hashtag and a link http://example.com!\"\n",
    "cleaned_text = remove_noise(sentence)\n",
    "\n",
    "print(\"Original Sentence:\", sentence)\n",
    "print(\"Cleaned Sentence:\", cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16b54a9",
   "metadata": {},
   "source": [
    "# Remove emojis and emoticons from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2236f361-6e25-4bca-8c32-98fc7dffa604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: This is a sample tweet with #hashtag, a link http://example.com, and an emoji ðŸ˜Š, along with an emoticon :D.\n",
      "Cleaned Sentence: This is a sample tweet with  a link  and an emoji  along with an emoticon D\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import emoji\n",
    "\n",
    "def remove_noise(text):\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remove emojis\n",
    "    text = emoji.replace_emoji(text, replace='')  \n",
    "    \n",
    "    # Remove common emoticons like :) or :-(\n",
    "    text = re.sub(r'[:;=8][\\-o*\\']?[)D(\\[]', '', text) \n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "sentence = \"This is a sample tweet with #hashtag, a link http://example.com, and an emoji ðŸ˜Š, along with an emoticon :D.\"\n",
    "cleaned_text = remove_noise(sentence)\n",
    "\n",
    "print(\"Original Sentence:\", sentence)\n",
    "print(\"Cleaned Sentence:\", cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9d194a",
   "metadata": {},
   "source": [
    "# Normalize text by removing whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "778fd0c9-ab5d-4d72-9f8a-e99fc4ec5670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence:   This   is   a   sample   Text  with  EXTRA   spaces.  \n",
      "Normalized Sentence: this is a sample text with extra spaces.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "sentence = \"  This   is   a   sample   Text  with  EXTRA   spaces.  \"\n",
    "normalized_text = normalize_text(sentence)\n",
    "\n",
    "# Displaying output\n",
    "print(\"Original Sentence:\", sentence)\n",
    "print(\"Normalized Sentence:\", normalized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e37eef",
   "metadata": {},
   "source": [
    "# Extract all dates in various formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d26184d-6322-46c9-a9c1-4c7815128b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: The event is on 12/05/2023, another meeting is scheduled for Dec 25, 2024, and 03-15-2022 was a holiday.\n",
      "Extracted Dates: ['12/05/2023', '03-15-2022', 'Dec 25, 2024']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_dates(text):\n",
    "    date_patterns = [\n",
    "        r'\\b\\d{1,2}/\\d{1,2}/\\d{4}\\b',  # DD/MM/YYYY\n",
    "        r'\\b\\d{1,2}-\\d{1,2}-\\d{4}\\b',  # MM-DD-YYYY\n",
    "        r'\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{1,2}, \\d{4}\\b'  # Month Day, Year\n",
    "    ]\n",
    "    dates = []\n",
    "    for pattern in date_patterns:\n",
    "        dates.extend(re.findall(pattern, text))\n",
    "    return dates\n",
    "\n",
    "# Example usage\n",
    "sentence = \"The event is on 12/05/2023, another meeting is scheduled for Dec 25, 2024, and 03-15-2022 was a holiday.\"\n",
    "dates = extract_dates(sentence)\n",
    "\n",
    "# Displaying output\n",
    "print(\"Original Sentence:\", sentence)\n",
    "print(\"Extracted Dates:\", dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c5d2c7",
   "metadata": {},
   "source": [
    "# Extract phone numbers in various formats and standardize to a certain format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c549167-5713-42f8-9040-5f17ce0026e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: Contact me at (123) 456-7890 or +1 987-654-3210. Call 415.555.2678 for support.\n",
      "Extracted and Standardized Phone Numbers: ['987-654-3210', '415-555-2678']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_phone_numbers(text):\n",
    "    phone_pattern = r'\\b(?:\\+\\d{1,2}\\s?)?(?:\\(\\d{3}\\)|\\d{3})[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b'\n",
    "    phone_numbers = re.findall(phone_pattern, text)\n",
    "    standardized_numbers = [re.sub(r'[-.\\s]', '-', num) for num in phone_numbers]\n",
    "    return standardized_numbers\n",
    "\n",
    "# Example usage\n",
    "sentence = \"Contact me at (123) 456-7890 or +1 987-654-3210. Call 415.555.2678 for support.\"\n",
    "phone_numbers = extract_phone_numbers(sentence)\n",
    "\n",
    "# Displaying output\n",
    "print(\"Original Sentence:\", sentence)\n",
    "print(\"Extracted and Standardized Phone Numbers:\", phone_numbers)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
