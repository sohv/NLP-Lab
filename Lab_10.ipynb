{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohv/NLP-Lab/blob/main/Lab_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i76V2uLtscP-"
      },
      "source": [
        "# Hidden Markov Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text-classification using HMM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 1 0]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np  \n",
        "from hmmlearn import hmm  \n",
        "from sklearn.feature_extraction.text import CountVectorizer  \n",
        "\n",
        "texts = [\"I love programming\", \"Python is great\", \"I hate bugs\", \"Debugging is hard\"]  \n",
        "labels = [1, 1, 0, 0]  \n",
        "\n",
        "vectorizer = CountVectorizer(binary=True)  \n",
        "X = vectorizer.fit_transform(texts).toarray()  \n",
        "\n",
        "lengths = [len(seq) for seq in X]\n",
        "\n",
        "X_reshaped = np.concatenate(X).reshape(-1, 1)\n",
        "\n",
        "model = hmm.GaussianHMM(n_components=2, covariance_type=\"diag\", n_iter=100)\n",
        "model.fit(X_reshaped, [sum(lengths)]) \n",
        "\n",
        "# predict sentiment\n",
        "preds = model.predict(X_reshaped).reshape(len(texts), -1)[:, 0] \n",
        "print(preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPQAGYDcsegK"
      },
      "source": [
        "## Cross-domain classification using HMM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-w7mHtwsUKl",
        "outputId": "367629a6-ea8f-43d9-ff70-2a691a454072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Domain Classification Accuracy: 0.40\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tag import hmm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "def load_data():\n",
        "    categories_tech = ['comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware']\n",
        "    categories_health = ['sci.med']\n",
        "\n",
        "    tech_data = fetch_20newsgroups(subset='train', categories=categories_tech, remove=('headers', 'footers', 'quotes'))\n",
        "    health_data = fetch_20newsgroups(subset='test', categories=categories_health, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "    return tech_data.data, tech_data.target, health_data.data, health_data.target\n",
        "\n",
        "def preprocess_data(train_texts, test_texts):\n",
        "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "    X_train = vectorizer.fit_transform(train_texts)\n",
        "    X_test = vectorizer.transform(test_texts)\n",
        "    return X_train, X_test, vectorizer\n",
        "\n",
        "def train_hmm(X_train, y_train):\n",
        "    le = LabelEncoder()\n",
        "    y_train_encoded = le.fit_transform(y_train)\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X_train, y_train_encoded)\n",
        "    return model, le\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, le):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_labels = le.inverse_transform(y_pred)\n",
        "    accuracy = accuracy_score(y_test, y_pred_labels)\n",
        "    print(f\"Cross-Domain Classification Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "def main():\n",
        "    train_texts, train_labels, test_texts, test_labels = load_data()\n",
        "    X_train, X_test, vectorizer = preprocess_data(train_texts, test_texts)\n",
        "    model, le = train_hmm(X_train, train_labels)\n",
        "    evaluate_model(model, X_test, test_labels, le)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HMM successfully scored 396/396 health docs.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from hmmlearn.hmm import GaussianHMM\n",
        "\n",
        "# load tech and health documents\n",
        "tech = fetch_20newsgroups(subset='train', categories=['comp.graphics'], remove=('headers', 'footers', 'quotes'))\n",
        "health = fetch_20newsgroups(subset='test', categories=['sci.med'], remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# TF-IDF\n",
        "vec = TfidfVectorizer(max_features=50)\n",
        "X_all = vec.fit_transform(tech.data + health.data).toarray()\n",
        "X_tech = X_all[:len(tech.data)]\n",
        "X_health = X_all[len(tech.data):]\n",
        "\n",
        "def repeat_seq(X, times=10):\n",
        "    return np.vstack([np.tile(x, (times, 1)) for x in X]), [times] * len(X)\n",
        "\n",
        "X_train, lengths = repeat_seq(X_tech, times=5)\n",
        "\n",
        "model = GaussianHMM(n_components=5, covariance_type='diag', n_iter=100).fit(X_train, lengths)\n",
        "\n",
        "scores = []\n",
        "for x in X_health:\n",
        "    x_rep = np.tile(x, (5, 1))\n",
        "    try:\n",
        "        scores.append(model.score(x_rep))\n",
        "    except:\n",
        "        scores.append(None)\n",
        "\n",
        "valid_scores = [s for s in scores if s is not None]\n",
        "print(f\"HMM successfully scored {len(valid_scores)}/{len(scores)} health docs.\")\n",
        "#print(\"Sample scores:\", valid_scores[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giFdyALbxABj"
      },
      "source": [
        "## Hybrid HMM-Naive Bayes for text classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu3abINGwvMk",
        "outputId": "470b8a11-3cf1-432b-d38f-8a8145a62d9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hybrid HMM+NaiveBayes accuracy: 0.5481049562682215\n",
            "Standalone HMM accuracy: 0.5335276967930029\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from hmmlearn import hmm\n",
        "\n",
        "nltk.download('punkt', quiet=True)\n",
        "categories = ['comp.graphics', 'sci.med']\n",
        "data = fetch_20newsgroups(subset='train', categories=categories, remove=('headers','footers','quotes'))\n",
        "texts = data.data\n",
        "labels = data.target  \n",
        "\n",
        "# Tokenize\n",
        "tokens = [nltk.word_tokenize(doc.lower())[:30] for doc in texts]  # limit to 30 words\n",
        "tokens = [t for t in tokens if len(t) >= 5]  # filter short ones\n",
        "labels = [labels[i] for i in range(len(tokens))]  # align labels\n",
        "\n",
        "le = LabelEncoder().fit(sum(tokens, []))\n",
        "seqs = [le.transform([w for w in t if w in le.classes_]) for t in tokens]\n",
        "lens = [len(s) for s in seqs]\n",
        "X = np.concatenate(seqs).reshape(-1, 1)\n",
        "\n",
        "model = hmm.GaussianHMM(n_components=5, n_iter=100).fit(X, lengths=lens)\n",
        "posteriors = []\n",
        "start = 0\n",
        "for l in lens:\n",
        "    probs = model.predict_proba(X[start:start+l])\n",
        "    posteriors.append(probs.mean(axis=0)) \n",
        "    start += l\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(posteriors, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "nb = GaussianNB().fit(X_train, y_train)\n",
        "hybrid_preds = nb.predict(X_test)\n",
        "\n",
        "state_class_map = {}\n",
        "for state in range(model.n_components):\n",
        "    state_class_map[state] = max(set(y_train), key=lambda c: sum(\n",
        "        1 for i, x in enumerate(X_train) if np.argmax(x) == state and y_train[i] == c\n",
        "    ))\n",
        "\n",
        "hmm_preds = [state_class_map[np.argmax(x)] for x in X_test]\n",
        "\n",
        "print(\"Hybrid HMM+NaiveBayes accuracy:\", accuracy_score(y_test, hybrid_preds))\n",
        "print(\"Standalone HMM accuracy:\", accuracy_score(y_test, hmm_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyZ7ha0bxM0x"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPbCtxMdbJ1MPxmFxVVAVPn",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
