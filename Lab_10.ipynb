{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbCtxMdbJ1MPxmFxVVAVPn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohv/NLP-Lab/blob/main/Lab_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hidden Markov Models"
      ],
      "metadata": {
        "id": "i76V2uLtscP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross-domain classification using HMM"
      ],
      "metadata": {
        "id": "NPQAGYDcsegK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-w7mHtwsUKl",
        "outputId": "367629a6-ea8f-43d9-ff70-2a691a454072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Domain Classification Accuracy: 0.40\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tag import hmm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "def load_data():\n",
        "    categories_tech = ['comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware']\n",
        "    categories_health = ['sci.med']\n",
        "\n",
        "    tech_data = fetch_20newsgroups(subset='train', categories=categories_tech, remove=('headers', 'footers', 'quotes'))\n",
        "    health_data = fetch_20newsgroups(subset='test', categories=categories_health, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "    return tech_data.data, tech_data.target, health_data.data, health_data.target\n",
        "\n",
        "def preprocess_data(train_texts, test_texts):\n",
        "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "    X_train = vectorizer.fit_transform(train_texts)\n",
        "    X_test = vectorizer.transform(test_texts)\n",
        "    return X_train, X_test, vectorizer\n",
        "\n",
        "def train_hmm(X_train, y_train):\n",
        "    le = LabelEncoder()\n",
        "    y_train_encoded = le.fit_transform(y_train)\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X_train, y_train_encoded)\n",
        "    return model, le\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, le):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_labels = le.inverse_transform(y_pred)\n",
        "    accuracy = accuracy_score(y_test, y_pred_labels)\n",
        "    print(f\"Cross-Domain Classification Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "def main():\n",
        "    train_texts, train_labels, test_texts, test_labels = load_data()\n",
        "    X_train, X_test, vectorizer = preprocess_data(train_texts, test_texts)\n",
        "    model, le = train_hmm(X_train, train_labels)\n",
        "    evaluate_model(model, X_test, test_labels, le)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hybrid HMM-Naive Bayes for text classification"
      ],
      "metadata": {
        "id": "giFdyALbxABj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tag import hmm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "def load_data():\n",
        "    categories = ['comp.graphics', 'sci.med']\n",
        "    data = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "    return data.data, data.target\n",
        "\n",
        "def preprocess_data(texts):\n",
        "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "    X = vectorizer.fit_transform(texts)\n",
        "    return X, vectorizer\n",
        "\n",
        "def train_hmm(X_train, y_train):\n",
        "    le = LabelEncoder()\n",
        "    y_train_encoded = le.fit_transform(y_train)\n",
        "    hmm_model = MultinomialNB()\n",
        "    hmm_model.fit(X_train, y_train_encoded)\n",
        "    return hmm_model, le\n",
        "\n",
        "def extract_hmm_features(hmm_model, X):\n",
        "    return hmm_model.predict_proba(X)\n",
        "\n",
        "def train_naive_bayes(X_train, y_train):\n",
        "    nb_model = MultinomialNB()\n",
        "    nb_model.fit(X_train, y_train)\n",
        "    return nb_model\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, le, model_name):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_labels = le.inverse_transform(y_pred)\n",
        "    accuracy = accuracy_score(y_test, y_pred_labels)\n",
        "    print(f\"{model_name} Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "def main():\n",
        "    texts, labels = load_data()\n",
        "    X, vectorizer = preprocess_data(texts)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "    hmm_model, le = train_hmm(X_train, y_train)\n",
        "    evaluate_model(hmm_model, X_test, y_test, le, \"Standalone HMM\")\n",
        "\n",
        "    hmm_features_train = extract_hmm_features(hmm_model, X_train)\n",
        "    hmm_features_test = extract_hmm_features(hmm_model, X_test)\n",
        "\n",
        "    nb_model = train_naive_bayes(hmm_features_train, y_train)\n",
        "    evaluate_model(nb_model, hmm_features_test, y_test, le, \"Hybrid HMM-Naïve Bayes\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu3abINGwvMk",
        "outputId": "470b8a11-3cf1-432b-d38f-8a8145a62d9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standalone HMM Accuracy: 0.96\n",
            "Hybrid HMM-Naïve Bayes Accuracy: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tyZ7ha0bxM0x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}